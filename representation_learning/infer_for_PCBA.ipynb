{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad699271-b42f-4a21-9170-3797cd6fdf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "sys.path.append('../') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567a6322-3936-46ef-9cf5-1c8f57c18a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiongjiacheng/anaconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from demo.ConfSeq import get_ConfSeq_pair_from_mol,get_mol_from_ConfSeq_pair,randomize_mol\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from rdkit.Chem import rdmolops, rdchem\n",
    "from tqdm.contrib.concurrent import process_map  \n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from transformers import BartForConditionalGeneration, BartConfig\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rdkit.ML.Scoring import Scoring\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77586fbe-68be-4e24-ab8c-714cd57741c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [chr(i) for i in range(33, 127)] \n",
    "\n",
    "for i in range(-180,180):\n",
    "    vocab.append('<'+str(i)+'>')\n",
    "\n",
    "vocab.append('<mask>')\n",
    "vocab.append('<unk>')\n",
    "vocab.append('<sos>')\n",
    "vocab.append('<eos>')\n",
    "vocab.append('<pad>')\n",
    "\n",
    "\n",
    "config = BartConfig()\n",
    "\n",
    "config.pad_token_id = vocab.index('<pad>')\n",
    "config.eos_token_id = vocab.index('<eos>')\n",
    "config.sos_token_id = vocab.index('<sos>')\n",
    "config.forced_eos_token_id = None\n",
    "config.encoder_layers = 6\n",
    "config.encoder_attention_heads = 8\n",
    "config.decoder_layers = 0\n",
    "config.decoder_attention_heads = 0\n",
    "config.d_model = 256\n",
    "# config.share_embeddings = True\n",
    "config.vocab_size = len(vocab)\n",
    "\n",
    "\n",
    "vocab_dict = {char: idx for idx, char in enumerate(vocab)}\n",
    "bart = BartForConditionalGeneration(config = config )\n",
    "\n",
    "\n",
    "class CustomBartEncoder(nn.Module):\n",
    "    def __init__(self, bart):\n",
    "        super().__init__()\n",
    "    \n",
    "        # 加载 BART 模型\n",
    "        self.bart_model = bart \n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        # 获取编码器输出\n",
    "        outputs = self.bart_model.model.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return outputs.last_hidden_state\n",
    "\n",
    "# 示例使用\n",
    "bart_encoder_model  = CustomBartEncoder(bart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26e0e75e-1470-4757-b1bd-9f0ce09a0acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_invalid_chirality(mol):\n",
    "    mol = copy.deepcopy(mol)\n",
    "    \"\"\"\n",
    "    找出分子中同时出现在三个环中的原子。\n",
    "    \n",
    "    参数:\n",
    "        mol: RDKit 分子对象\n",
    "    返回:\n",
    "        List[int]: 同时出现在三个环中的原子的索引列表\n",
    "    \"\"\"\n",
    "    # 获取分子的所有环（SSSR：最小集的简单环）\n",
    "    rings = rdmolops.GetSymmSSSR(mol)\n",
    "\n",
    "    # 创建一个字典，记录每个原子出现在多少个环中\n",
    "    atom_in_rings_count = {}\n",
    "\n",
    "    # 遍历所有环，统计每个原子出现的次数\n",
    "    for ring in rings:\n",
    "        for atom_idx in ring:\n",
    "            if atom_idx not in atom_in_rings_count:\n",
    "                atom_in_rings_count[atom_idx] = 0\n",
    "            atom_in_rings_count[atom_idx] += 1\n",
    "\n",
    "    # 找出那些同时出现在三个环中的原子\n",
    "    atoms_in_3_rings = [atom for atom, count in atom_in_rings_count.items() if count == 3]\n",
    "\n",
    "    for atom_idx in atoms_in_3_rings:\n",
    "        atom = mol.GetAtomWithIdx(atom_idx)\n",
    "        atom.SetChiralTag(rdchem.ChiralType.CHI_UNSPECIFIED)\n",
    "\n",
    "    return mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdc852f9-35e9-4855-b9fb-4daf58a4446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ConfSeq(query_mol):\n",
    "\n",
    "    if query_mol != None:\n",
    "        try:\n",
    "            query_mol = rm_invalid_chirality(query_mol)\n",
    "            query_mol = randomize_mol(query_mol)\n",
    "            Chem.MolToSmiles(query_mol)    \n",
    "            query_mol = Chem.RenumberAtoms(query_mol, eval(query_mol.GetProp('_smilesAtomOutputOrder'))) \n",
    "            Chem.MolToSmiles(query_mol,canonical = False)\n",
    "            query_mol = Chem.RenumberAtoms(query_mol, eval(query_mol.GetProp('_smilesAtomOutputOrder'))) \n",
    "            in_smiles,TD_smiles = get_ConfSeq_pair_from_mol(query_mol)\n",
    "            TD_smiles = TD_smiles.replace('<180>','<-180>')\n",
    "            \n",
    "        except:\n",
    "            in_smiles,TD_smiles = '',''            \n",
    "    else:\n",
    "        in_smiles,TD_smiles = '',''\n",
    "        \n",
    "    return TD_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ebf0abf-df09-4704-a613-953eedd7f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_for_seq(i):\n",
    "    int = [vocab_dict[i] for i in i.split(' ')] \n",
    "    int = torch.Tensor([int]).long()\n",
    "    embed = bart_encoder_model(int).mean(dim=1).tolist()[0]\n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d096fad4-99a1-46d4-90cd-8f65a86edc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.Tensor(self.data[idx]).long()\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data = batch  # 解压每个样本中的数据和标签\n",
    "    padded_data = pad_sequence(data, batch_first=True, padding_value = vocab.index('<pad>'))  # 对数据进行填充\n",
    "    return padded_data\n",
    "\n",
    "\n",
    "def mean_pooling(last_hidden_state, attention_mask):\n",
    "    # 对每个样本进行池化，忽略 pad 的位置\n",
    "    # 将 attention_mask 转换为 float 类型，并进行扩展\n",
    "    attention_mask = attention_mask.unsqueeze(-1).expand(last_hidden_state.size())\n",
    "    # 计算有效的特征总和和有效特征的数量\n",
    "    sum_embeddings = (last_hidden_state * attention_mask).sum(dim=1)\n",
    "    sum_mask = attention_mask.sum(dim=1)\n",
    "    # 计算平均池化，避免除以零\n",
    "    pooled_output = sum_embeddings / (sum_mask + 1e-8)  # 加小常数以避免除零\n",
    "    return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceda94ab-9451-4084-bb02-6ca6e47149bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfd49f30-96eb-4b53-9417-fe5711b82e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddcab9f1-015c-417b-a472-f39c8933b660",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 39/39 [00:02<00:00, 13.67it/s]\n",
      "100%|████████████████████████████████████████████| 39/39 [00:00<00:00, 801.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actives_seqs length: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/358579 [00:00<?, ?it/s]/tmp/ipykernel_2676189/438043969.py:38: TqdmWarning: Iterable length 358579 > 1000 but `chunksize` is not set. This may seriously degrade multiprocess performance. Set `chunksize=1` or more.\n",
      "  decoys_seqs = process_map(get_ConfSeq, tqdm(decoys_mols), max_workers = 32)\n",
      "100%|██████████████████████████████████| 358579/358579 [00:14<00:00, 24896.46it/s]\n",
      "100%|███████████████████████████████████| 358579/358579 [02:17<00:00, 2603.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoys_seqs length: 358579\n",
      "5lge_ligand_.sdf\n",
      "4xs3_ligand_.sdf\n",
      "5de1_ligand_.sdf\n",
      "5l57_ligand_.sdf\n",
      "4i3l_ligand_.sdf\n",
      "4umx_ligand_.sdf\n",
      "4xrx_ligand_.sdf\n",
      "6adg_ligand_.sdf\n",
      "6b0z_ligand_.sdf\n",
      "5sun_ligand_.sdf\n",
      "5l58_ligand_.sdf\n",
      "4i3k_ligand_.sdf\n",
      "5svf_ligand_.sdf\n",
      "5tqh_ligand_.sdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 24/24 [00:03<00:00,  6.45it/s]\n",
      "100%|████████████████████████████████████████████| 24/24 [00:00<00:00, 457.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actives_seqs length: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/4068 [00:00<?, ?it/s]/tmp/ipykernel_2676189/438043969.py:38: TqdmWarning: Iterable length 4068 > 1000 but `chunksize` is not set. This may seriously degrade multiprocess performance. Set `chunksize=1` or more.\n",
      "  decoys_seqs = process_map(get_ConfSeq, tqdm(decoys_mols), max_workers = 32)\n",
      "100%|████████████████████████████████████████| 4068/4068 [00:04<00:00, 880.37it/s]\n",
      "100%|███████████████████████████████████████| 4068/4068 [00:01<00:00, 2796.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoys_seqs length: 4068\n",
      "4prg_ligand_.sdf\n",
      "2i4j_ligand_.sdf\n",
      "1zgy_ligand_.sdf\n",
      "4fgy_ligand_.sdf\n",
      "2q5s_ligand_.sdf\n",
      "2p4y_ligand_.sdf\n",
      "3hod_ligand_.sdf\n",
      "5y2t_ligand_.sdf\n",
      "3r8a_ligand_.sdf\n",
      "4ci5_ligand_.sdf\n",
      "2yfe_ligand_.sdf\n",
      "5two_ligand_.sdf\n",
      "5tto_ligand_.sdf\n",
      "3b1m_ligand_.sdf\n",
      "5z5s_ligand_.sdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 13/13 [00:03<00:00,  3.75it/s]\n",
      "100%|████████████████████████████████████████████| 13/13 [00:00<00:00, 243.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actives_seqs length: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/4376 [00:00<?, ?it/s]/tmp/ipykernel_2676189/438043969.py:38: TqdmWarning: Iterable length 4376 > 1000 but `chunksize` is not set. This may seriously degrade multiprocess performance. Set `chunksize=1` or more.\n",
      "  decoys_seqs = process_map(get_ConfSeq, tqdm(decoys_mols), max_workers = 32)\n",
      "100%|███████████████████████████████████████| 4376/4376 [00:03<00:00, 1202.16it/s]\n",
      "100%|███████████████████████████████████████| 4376/4376 [00:01<00:00, 2921.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoys_seqs length: 4376\n",
      "5du5_ligand_.sdf\n",
      "2b1z_ligand_.sdf\n",
      "4ivw_ligand_.sdf\n",
      "2b1v_ligand_.sdf\n",
      "5e1c_ligand_.sdf\n",
      "2q70_ligand_.sdf\n",
      "5due_ligand_.sdf\n",
      "5dzi_ligand_.sdf\n",
      "4pps_ligand_.sdf\n",
      "2qr9_ligand_.sdf\n",
      "5drj_ligand_.sdf\n",
      "2qse_ligand_.sdf\n",
      "2p15_ligand_.sdf\n",
      "2qzo_ligand_.sdf\n",
      "1l2i_ligand_.sdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 24/24 [00:03<00:00,  6.95it/s]\n",
      "100%|████████████████████████████████████████████| 24/24 [00:00<00:00, 466.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actives_seqs length: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/269345 [00:00<?, ?it/s]/tmp/ipykernel_2676189/438043969.py:38: TqdmWarning: Iterable length 269345 > 1000 but `chunksize` is not set. This may seriously degrade multiprocess performance. Set `chunksize=1` or more.\n",
      "  decoys_seqs = process_map(get_ConfSeq, tqdm(decoys_mols), max_workers = 32)\n",
      "100%|██████████████████████████████████| 269345/269345 [00:12<00:00, 22443.12it/s]\n",
      "100%|███████████████████████████████████| 269345/269345 [01:33<00:00, 2869.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoys_seqs length: 269345\n",
      "6b73_ligand_.sdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 17/17 [00:04<00:00,  3.65it/s]\n",
      "100%|████████████████████████████████████████████| 17/17 [00:00<00:00, 399.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actives_seqs length: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/311600 [00:00<?, ?it/s]/tmp/ipykernel_2676189/438043969.py:38: TqdmWarning: Iterable length 311600 > 1000 but `chunksize` is not set. This may seriously degrade multiprocess performance. Set `chunksize=1` or more.\n",
      "  decoys_seqs = process_map(get_ConfSeq, tqdm(decoys_mols), max_workers = 32)\n",
      "100%|██████████████████████████████████| 311600/311600 [00:15<00:00, 20187.91it/s]\n",
      "100%|███████████████████████████████████| 311600/311600 [01:56<00:00, 2676.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoys_seqs length: 311600\n",
      "4ldl_ligand_.sdf\n",
      "3sn6_ligand_.sdf\n",
      "4qkx_ligand_.sdf\n",
      "3pds_ligand_.sdf\n",
      "4lde_ligand_.sdf\n",
      "6mxt_ligand_.sdf\n",
      "3p0g_ligand_.sdf\n",
      "4ldo_ligand_.sdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 546/546 [00:04<00:00, 115.04it/s]\n",
      "100%|█████████████████████████████████████████| 546/546 [00:00<00:00, 1869.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actives_seqs length: 546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/244552 [00:00<?, ?it/s]/tmp/ipykernel_2676189/438043969.py:38: TqdmWarning: Iterable length 244552 > 1000 but `chunksize` is not set. This may seriously degrade multiprocess performance. Set `chunksize=1` or more.\n",
      "  decoys_seqs = process_map(get_ConfSeq, tqdm(decoys_mols), max_workers = 32)\n",
      "100%|██████████████████████████████████| 244552/244552 [00:14<00:00, 17008.79it/s]\n",
      "100%|███████████████████████████████████| 244552/244552 [01:31<00:00, 2684.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoys_seqs length: 244552\n",
      "5x1v_ligand_.sdf\n",
      "3h6o_ligand_.sdf\n",
      "3u2z_ligand_.sdf\n",
      "3me3_ligand_.sdf\n",
      "3gqy_ligand_.sdf\n",
      "4g1n_ligand_.sdf\n",
      "4jpg_ligand_.sdf\n",
      "5x1w_ligand_.sdf\n",
      "3gr4_ligand_.sdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 653/653 [00:04<00:00, 135.06it/s]\n",
      "100%|█████████████████████████████████████████| 653/653 [00:00<00:00, 2210.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actives_seqs length: 653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/262483 [00:00<?, ?it/s]/tmp/ipykernel_2676189/438043969.py:38: TqdmWarning: Iterable length 262483 > 1000 but `chunksize` is not set. This may seriously degrade multiprocess performance. Set `chunksize=1` or more.\n",
      "  decoys_seqs = process_map(get_ConfSeq, tqdm(decoys_mols), max_workers = 32)\n",
      "100%|██████████████████████████████████| 262483/262483 [00:15<00:00, 17336.18it/s]\n",
      "100%|███████████████████████████████████| 262483/262483 [01:40<00:00, 2609.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoys_seqs length: 262483\n",
      "3a2j_ligand_.sdf\n",
      "3a2i_ligand_.sdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/5362 [00:00<?, ?it/s]/tmp/ipykernel_2676189/438043969.py:35: TqdmWarning: Iterable length 5362 > 1000 but `chunksize` is not set. This may seriously degrade multiprocess performance. Set `chunksize=1` or more.\n",
      "  actives_seqs = process_map(get_ConfSeq, tqdm(actives_mols), max_workers = 32)\n",
      "100%|████████████████████████████████████████| 5362/5362 [00:05<00:00, 960.42it/s]\n",
      "100%|███████████████████████████████████████| 5362/5362 [00:02<00:00, 2264.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actives_seqs length: 5362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/101771 [00:00<?, ?it/s]/tmp/ipykernel_2676189/438043969.py:38: TqdmWarning: Iterable length 101771 > 1000 but `chunksize` is not set. This may seriously degrade multiprocess performance. Set `chunksize=1` or more.\n",
      "  decoys_seqs = process_map(get_ConfSeq, tqdm(decoys_mols), max_workers = 32)\n",
      "100%|███████████████████████████████████| 101771/101771 [00:10<00:00, 9764.91it/s]\n",
      "100%|███████████████████████████████████| 101771/101771 [00:37<00:00, 2678.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoys_seqs length: 101771\n",
      "5l2m_ligand_.sdf\n",
      "5l2o_ligand_.sdf\n",
      "5l2n_ligand_.sdf\n",
      "4x4l_ligand_.sdf\n",
      "4wpn_ligand_.sdf\n",
      "5ac2_ligand_.sdf\n",
      "5tei_ligand_.sdf\n",
      "4wp7_ligand_.sdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 97/97 [00:05<00:00, 16.25it/s]\n",
      "100%|████████████████████████████████████████████| 97/97 [00:00<00:00, 751.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actives_seqs length: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/32952 [00:00<?, ?it/s]/tmp/ipykernel_2676189/438043969.py:38: TqdmWarning: Iterable length 32952 > 1000 but `chunksize` is not set. This may seriously degrade multiprocess performance. Set `chunksize=1` or more.\n",
      "  decoys_seqs = process_map(get_ConfSeq, tqdm(decoys_mols), max_workers = 32)\n",
      "100%|█████████████████████████████████████| 32952/32952 [00:07<00:00, 4317.21it/s]\n",
      "100%|█████████████████████████████████████| 32952/32952 [00:13<00:00, 2467.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoys_seqs length: 32952\n",
      "1fap_ligand_.sdf\n",
      "1nsg_ligand_.sdf\n",
      "3fap_ligand_.sdf\n",
      "5gpg_ligand_.sdf\n",
      "4fap_ligand_.sdf\n",
      "4jt5_ligand_.sdf\n",
      "4drh_ligand_.sdf\n",
      "4drj_ligand_.sdf\n",
      "4jsx_ligand_.sdf\n",
      "4dri_ligand_.sdf\n",
      "2fap_ligand_.sdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 308/308 [00:05<00:00, 57.73it/s]\n",
      "100%|█████████████████████████████████████████| 308/308 [00:00<00:00, 1635.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actives_seqs length: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/61461 [00:00<?, ?it/s]/tmp/ipykernel_2676189/438043969.py:38: TqdmWarning: Iterable length 61461 > 1000 but `chunksize` is not set. This may seriously degrade multiprocess performance. Set `chunksize=1` or more.\n",
      "  decoys_seqs = process_map(get_ConfSeq, tqdm(decoys_mols), max_workers = 32)\n",
      "100%|█████████████████████████████████████| 61461/61461 [00:08<00:00, 7613.43it/s]\n",
      "100%|█████████████████████████████████████| 61461/61461 [00:20<00:00, 2935.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoys_seqs length: 61461\n",
      "6g9h_ligand_.sdf\n",
      "2ojg_ligand_.sdf\n",
      "4qta_ligand_.sdf\n",
      "5v62_ligand_.sdf\n",
      "4qte_ligand_.sdf\n",
      "4qp4_ligand_.sdf\n",
      "1pme_ligand_.sdf\n",
      "4xj0_ligand_.sdf\n",
      "5buj_ligand_.sdf\n",
      "3w55_ligand_.sdf\n",
      "3sa0_ligand_.sdf\n",
      "4qp9_ligand_.sdf\n",
      "4zzn_ligand_.sdf\n",
      "5ax3_ligand_.sdf\n",
      "4qp3_ligand_.sdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 163/163 [00:04<00:00, 33.86it/s]\n",
      "100%|█████████████████████████████████████████| 163/163 [00:00<00:00, 1292.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actives_seqs length: 163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/291039 [00:00<?, ?it/s]/tmp/ipykernel_2676189/438043969.py:38: TqdmWarning: Iterable length 291039 > 1000 but `chunksize` is not set. This may seriously degrade multiprocess performance. Set `chunksize=1` or more.\n",
      "  decoys_seqs = process_map(get_ConfSeq, tqdm(decoys_mols), max_workers = 32)\n",
      "100%|██████████████████████████████████| 291039/291039 [00:14<00:00, 20669.76it/s]\n",
      "100%|███████████████████████████████████| 291039/291039 [01:38<00:00, 2966.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoys_seqs length: 291039\n",
      "2xwd_ligand_.sdf\n",
      "3ril_ligand_.sdf\n",
      "3rik_ligand_.sdf\n",
      "2xwe_ligand_.sdf\n",
      "2v3d_ligand_.sdf\n",
      "2v3e_ligand_.sdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 360/360 [00:05<00:00, 71.57it/s]\n",
      "100%|█████████████████████████████████████████| 360/360 [00:00<00:00, 1698.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actives_seqs length: 360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/350540 [00:00<?, ?it/s]/tmp/ipykernel_2676189/438043969.py:38: TqdmWarning: Iterable length 350540 > 1000 but `chunksize` is not set. This may seriously degrade multiprocess performance. Set `chunksize=1` or more.\n",
      "  decoys_seqs = process_map(get_ConfSeq, tqdm(decoys_mols), max_workers = 32)\n",
      "100%|██████████████████████████████████| 350540/350540 [00:18<00:00, 18756.38it/s]\n",
      "100%|███████████████████████████████████| 350540/350540 [02:05<00:00, 2796.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoys_seqs length: 350540\n",
      "5fv7_ligand_.sdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 64/64 [00:06<00:00, 10.02it/s]\n",
      "100%|███████████████████████████████████████████| 64/64 [00:00<00:00, 1057.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actives_seqs length: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/3344 [00:00<?, ?it/s]/tmp/ipykernel_2676189/438043969.py:38: TqdmWarning: Iterable length 3344 > 1000 but `chunksize` is not set. This may seriously degrade multiprocess performance. Set `chunksize=1` or more.\n",
      "  decoys_seqs = process_map(get_ConfSeq, tqdm(decoys_mols), max_workers = 32)\n",
      "100%|████████████████████████████████████████| 3344/3344 [00:06<00:00, 502.81it/s]\n",
      "100%|███████████████████████████████████████| 3344/3344 [00:01<00:00, 3016.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoys_seqs length: 3344\n",
      "2vuk_ligand_.sdf\n",
      "4agq_ligand_.sdf\n",
      "4ago_ligand_.sdf\n",
      "5g4o_ligand_.sdf\n",
      "3zme_ligand_.sdf\n",
      "5o1i_ligand_.sdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 88/88 [00:06<00:00, 14.43it/s]\n",
      "100%|███████████████████████████████████████████| 88/88 [00:00<00:00, 1106.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actives_seqs length: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/3818 [00:00<?, ?it/s]/tmp/ipykernel_2676189/438043969.py:38: TqdmWarning: Iterable length 3818 > 1000 but `chunksize` is not set. This may seriously degrade multiprocess performance. Set `chunksize=1` or more.\n",
      "  decoys_seqs = process_map(get_ConfSeq, tqdm(decoys_mols), max_workers = 32)\n",
      "100%|████████████████████████████████████████| 3818/3818 [00:06<00:00, 591.39it/s]\n",
      "100%|███████████████████████████████████████| 3818/3818 [00:01<00:00, 3115.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoys_seqs length: 3818\n",
      "3dt3_ligand_.sdf\n",
      "6b0f_ligand_.sdf\n",
      "6chw_ligand_.sdf\n",
      "2iog_ligand_.sdf\n",
      "2r6w_ligand_.sdf\n",
      "5fqv_ligand_.sdf\n",
      "2pog_ligand_.sdf\n",
      "1xp1_ligand_.sdf\n",
      "2ayr_ligand_.sdf\n",
      "1xqc_ligand_.sdf\n",
      "2iok_ligand_.sdf\n",
      "5t92_ligand_.sdf\n",
      "5ufx_ligand_.sdf\n",
      "5aau_ligand_.sdf\n",
      "2ouz_ligand_.sdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 194/194 [00:05<00:00, 34.79it/s]\n",
      "100%|█████████████████████████████████████████| 194/194 [00:00<00:00, 1108.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actives_seqs length: 194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/342518 [00:00<?, ?it/s]/tmp/ipykernel_2676189/438043969.py:38: TqdmWarning: Iterable length 342518 > 1000 but `chunksize` is not set. This may seriously degrade multiprocess performance. Set `chunksize=1` or more.\n",
      "  decoys_seqs = process_map(get_ConfSeq, tqdm(decoys_mols), max_workers = 32)\n",
      "100%|██████████████████████████████████| 342518/342518 [00:18<00:00, 18526.40it/s]\n",
      "100%|███████████████████████████████████| 342518/342518 [01:57<00:00, 2926.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoys_seqs length: 342518\n",
      "5h84_ligand_.sdf\n",
      "5h86_ligand_.sdf\n",
      "5mlj_ligand_.sdf\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('./checkpoints/model_epoch_1.pth', map_location='cpu')  # 使用适当的设备    \n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in checkpoint.items():\n",
    "    if k.startswith('module.'):\n",
    "        new_state_dict[k[7:]] = v\n",
    "    else:\n",
    "        new_state_dict[k] = v\n",
    "\n",
    "bart_encoder_model.load_state_dict(new_state_dict)\n",
    "bart_encoder_model.eval()\n",
    "\n",
    "\n",
    "lis = os.listdir('./data/PCBA/AVE_unbiased/')\n",
    "lis = [i for i in lis if i[-4:] != '.txt']\n",
    "\n",
    "for name in lis[:]:\n",
    "\n",
    "    os.makedirs('./data/PCBA/AVE_unbiased_result/{}/'.format(name), exist_ok=True)\n",
    "    \n",
    "    file_lis = os.listdir('./data/PCBA/AVE_unbiased/{}/'.format(name))\n",
    "    file_lis = [i for i in file_lis if 'ligand_.sdf' in i]\n",
    "\n",
    "    suppl = Chem.SDMolSupplier('./data/PCBA/AVE_unbiased/{}/actives.sdf'.format(name))\n",
    "    # 将有效的分子（非 None）保存在列表中\n",
    "    actives_mols = [mol for mol in suppl if mol is not None]\n",
    "    actives_mols_atom_num = [i.GetNumAtoms() for i in actives_mols]\n",
    "    \n",
    "    suppl = Chem.SDMolSupplier('./data/PCBA/AVE_unbiased/{}/inactives.sdf'.format(name))\n",
    "    # 将有效的分子（非 None）保存在列表中\n",
    "    decoys_mols = [mol for mol in suppl if mol is not None]\n",
    "    decoys_mols_atom_num = [i.GetNumAtoms() for i in decoys_mols]\n",
    "\n",
    "\n",
    "    actives_seqs = process_map(get_ConfSeq, tqdm(actives_mols), max_workers = 32)\n",
    "    print('actives_seqs length:',len(actives_seqs))\n",
    "    \n",
    "    decoys_seqs = process_map(get_ConfSeq, tqdm(decoys_mols), max_workers = 32)\n",
    "    print('decoys_seqs length:',len(decoys_seqs))\n",
    "\n",
    "    with open('./data/PCBA/AVE_unbiased_result/{}/actives_seqs.txt'.format(name),'w+') as f:\n",
    "        f.write('\\n'.join(actives_seqs))\n",
    "\n",
    "    with open('./data/PCBA/AVE_unbiased_result/{}/decoys_seqs.txt'.format(name),'w+') as f:\n",
    "        f.write('\\n'.join(decoys_seqs))\n",
    "\n",
    "\n",
    "    with open('./data/PCBA/AVE_unbiased/{}/actives_seqs.txt'.format(name),'r') as f:\n",
    "        content = f.read()\n",
    "    active_seqs = content.split('\\n')   \n",
    "    active_seqs = [i if i != '' else '*' for i in actives_seqs]    \n",
    "    \n",
    "    with open('./data/PCBA/AVE_unbiased/{}/decoys_seqs.txt'.format(name),'r') as f:\n",
    "        content = f.read()\n",
    "    decoys_seqs = content.split('\\n') \n",
    "    decoys_seqs = [i if i != '' else '*' for i in decoys_seqs]\n",
    "\n",
    "\n",
    "    active_ints = [[vocab_dict[i] for i in seq.split(' ')] for seq in actives_seqs]\n",
    "    active_dataset = TensorDataset(active_ints)\n",
    "    active_dataloader = DataLoader(active_dataset, batch_size=128,collate_fn=collate_fn)\n",
    "\n",
    "    bart_encoder_model.to(device)\n",
    "    \n",
    "    active_embeds = []\n",
    "    \n",
    "    with torch.no_grad():  # 取消梯度计算\n",
    "    \n",
    "        for input_ids in active_dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = (input_ids != vocab.index('<pad>')).long() # 创建 attention mask\n",
    "            # 编码\n",
    "            output = bart_encoder_model(input_ids,attention_mask)\n",
    "            pooled_output = mean_pooling(output, attention_mask)\n",
    "            active_embeds.append(pooled_output)\n",
    "    \n",
    "    active_embeds = torch.cat(tuple(active_embeds), dim=0).to('cpu')\n",
    "\n",
    "    inactive_ints = [[vocab_dict[i] for i in seq.split(' ')] for seq in decoys_seqs]\n",
    "    inactive_dataset = TensorDataset(inactive_ints)\n",
    "    inactive_dataloader = DataLoader(inactive_dataset, batch_size=128,collate_fn=collate_fn)\n",
    "\n",
    "    \n",
    "    inactive_embeds = []\n",
    "    \n",
    "    with torch.no_grad():  # 取消梯度计算\n",
    "    \n",
    "        for input_ids in inactive_dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = (input_ids != vocab.index('<pad>')).long() # 创建 attention mask\n",
    "            # 编码\n",
    "            output = bart_encoder_model(input_ids,attention_mask)\n",
    "            pooled_output = mean_pooling(output, attention_mask)\n",
    "            inactive_embeds.append(pooled_output)\n",
    "    \n",
    "    inactive_embeds = torch.cat(tuple(inactive_embeds), dim=0).to('cpu')\n",
    "\n",
    "    \n",
    "    fingerprints = np.vstack([active_embeds,inactive_embeds])\n",
    "    labels = np.array([1] * len(active_embeds) + [0] * len(inactive_embeds))  # 活性为1，非活性为0   \n",
    "\n",
    "    mols_atom_num = np.array(actives_mols_atom_num + decoys_mols_atom_num)\n",
    "    \n",
    "    for file in file_lis:    \n",
    "        print(file)\n",
    "\n",
    "        query_mol = Chem.MolFromMolFile('./data/PCBA/AVE_unbiased/{}/{}'.format(name,file))\n",
    "        query_mol_atom_num = query_mol.GetNumAtoms()\n",
    "        \n",
    "        bart_encoder_model.to(torch.device('cpu'))\n",
    "        query_embeds = get_embedding_for_seq(get_ConfSeq(query_mol))\n",
    "        query_embeds = torch.Tensor(query_embeds)\n",
    "        euclidean_distance = torch.sqrt(torch.sum((query_embeds - fingerprints ) ** 2,dim = -1))\n",
    "        similarity_score = 1 / (1 + euclidean_distance)\n",
    "\n",
    "        factor = 2 * mols_atom_num/ (query_mol_atom_num + mols_atom_num)\n",
    "        similarity_score = similarity_score * factor\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(labels.tolist(), similarity_score.tolist())\n",
    "        \n",
    "        # 计算 AUC\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        similarity_score_np = similarity_score.numpy()\n",
    "        sort_idx = np.argsort(-similarity_score_np)\n",
    "        sorted_scores = similarity_score_np[sort_idx]\n",
    "        sorted_labels = labels[sort_idx].astype(bool)\n",
    "        score_data = np.column_stack((sorted_scores, sorted_labels))\n",
    "\n",
    "        bedroc_rdkit = Scoring.CalcBEDROC(score_data, col=1, alpha=80.5)\n",
    "        ef_1 = Scoring.CalcEnrichment(score_data, col=1, fractions=[0.01])[0]\n",
    "        ef_5 = Scoring.CalcEnrichment(score_data, col=1, fractions=[0.05])[0]\n",
    "\n",
    "        # 构造结果行\n",
    "        row = {\n",
    "            \"Protein\": name,\n",
    "            \"Ligand_File\": file,\n",
    "            \"ROC_AUC\": round(roc_auc, 4),\n",
    "            \"BEDROC\": round(bedroc_rdkit, 4),\n",
    "            \"EF5%\": round(ef_5, 4),\n",
    "            \"EF1%\": round(ef_1, 4)\n",
    "        }\n",
    "\n",
    "        # 写入 CSV 文件：如果文件不存在，则写入表头，否则追加行\n",
    "        csv_path = f'./PCBA_evaluation_result.csv'\n",
    "        if not os.path.exists(csv_path):\n",
    "            df = pd.DataFrame([row])\n",
    "            df.to_csv(csv_path, index=False)\n",
    "        else:\n",
    "            df = pd.DataFrame([row])\n",
    "            df.to_csv(csv_path, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b80dc-8106-40d1-87ab-a892d5558600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10978b8e-4d85-459c-94f7-e7388ed56384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205ac9c4-6709-41e1-9f4a-eb78bdf0f55b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
